<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143252559-1"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());
		  gtag('config', 'UA-143252559-1');
		</script>
		<!--  -->
		<title>Mariko Isogawa's page</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/avatar.png" alt="" /></a>
					<br>
					Mariko Isogawa, Ph.D.
					<br>
					firstname.lastname[at]ieee.org
					<br>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
							<h2>Welcome!</h2>
						</header>
						<p>I am a researcher at NTT Media Intelligence Laboratories working with
							<a href="https://sites.google.com/site/mikamidan/">Dr. Dan Mikami</a>.
							<!--  -->
							Currently I am staying at Robotics Institute, Carnegie Mellon University as a Visiting Researcher under the supervision of <a href="http://www.cs.cmu.edu/~motoole2/">Prof. Matthew O'Toole</a> and <a href="http://www.cs.cmu.edu/~kkitani/">Prof. Kris Kitani</a>.
							<!--  -->
							I've received my Ph.D. at Graduate School of Engineering Science, Osaka University under the supervision of <a href="http://daisukeiwai.org/en/index.html">Prof. Daisuke Iwai</a> and <a href="https://kosuke-sato.jimdo.com/">Prof. Kosuke Sato</a>.
						</p>
						<p>Research Interests: computer vision (especially, image&video inpainting, learning based image quality assessment, computer vision towards sports performance enhancement)</p>
						<ul class="actions">
							<!-- <li><a href="#" class="button">Curriculum Vitae (PDF)</a></li> -->
						</ul>
					</section>

					<!-- Short Bio -->
					<section id="ShortBio">
						<header class="major">
							<h2>Short Bio</h2>
						</header>
						<p>
						2019-current --- Visiting Scholar at Robotics Institute, Carnegie Mellon University
						<br />
						2013-current --- Researcher at NTT Media Intelligence Laboratories
						<br />
						2016-2019 --- Ph.D. of Engineering, Osaka University, Japan
						<br />
						2011-2013 --- Master of Engineering, Osaka University, Japan (<em>1st Class Honor</em> in the division of System Science and Applied Informatics, the Graduate School of System Engineering)
						<br />
						2007-2011 --- Bachelor of Engineering, Osaka University, Japan</p>
					</section>

					<!-- Research Projects -->
					<section id="ResearchProjects">
						<header class="major">
							<h2>Research Projects</h2>
						</header>
						<p>
							<span class="image left"><img src="images/research_projects/ranking_data_generation.png" alt="" /></span>
							<strong>Training Data Generation without any Manual Operations for Learning-Based Preference Order Estimation (<em>IJCV 2018 (IF 6.0), BMVC 2017</em>).</strong>
							<br>
							<a href="https://link.springer.com/article/10.1007/s11263-018-1132-0">[Open Access Journal Paper]</a>
							<br>
							Image inpainting is widely acknowledged as a task whose results are quite difficult to evaluate objectively. Thus, existing learning-based image quality assessment (IQA) methods for inpainting require subjectively annotated data for training, which requires huge annotation cost. To overcome this issue, our proposed framework generates simulated failure results of inpainted images whose subjective qualities are controlled as the training data.
						</p>
						<p>
							<span class="image left"><img src="images/research_projects/mask_optimization.png" alt="" /></span>
							<strong>Mask Region Optimization for Image Inpainting (IEEE Access 2018, <em>MIRU 2018 Interactive Session Award</em>).</strong>
							<br>
							<a href="https://ieeexplore.ieee.org/document/8502030">[Open Access Journal Paper]</a>
							<br>
							In image inpainting, users draw a mask to specify the region. However, it is widely known that users typically need to adjust the mask region by trial and error until they obtain a desired naturally inpainting result, because inpainting quality is significantly affected by even a slight change in the mask. This manual masking takes a great deal of users’ working time and requires considerable input. To reduce such human labor, we propose the method for masked region optimization so that good inpainting results can be automatically obtained.
						</p>
						<p>
							<span class="image left"><img src="images/research_projects/learning_to_rank.png" alt="" /></span>
							<strong>Learning-to-Rank Based Preference Order Estimation for Inpainted Images (MTAP 2018, IEEE ISMAR 2015 poster).</strong>
							<br>
							<a href="https://link.springer.com/article/10.1007/s11042-018-6186-z">[Open Access Journal Paper]</a>
							<br>
							This paper proposes an image quality assessment (IQA) method for image inpainting, aiming at selecting the best one from a plurality of results. It is widely known
							that inpainting results vary largely with the method used for inpainting and the parameters set. Thus, in a typical use case, users need to manually select the
							inpainting method and the parameters that yield the best result. This manual selection takes a great deal of time and thus there is a great need for a way to automatically
							estimate the best result. Thus, we propose the method that solves this problem as a learning-based ordering task between inpainted images.
						</p>
						<p>
							<span class="image left"><img src="images/research_projects/lower_dimensional.png" alt="" /></span>
							<strong>Image and Video Inpainting via feature reduction and compensation (MTAP 2016, IEEE ISMAR 2015 poster, <em>IEICE MVE Award 2014</em>).</strong>
							<br>
							<a href="https://link.springer.com/article/10.1007/s11042-016-3550-8">[Open Access Journal Paper]</a>
							<br>
							Most existing image inpainting methods fail when similar regions do not exist in undamaged regions or dataset. To overcome this, our approach creates similar
							regions by projecting a low dimensional space from the original space. The approach comprises three stages. First, input images/videos are converted to a lower
							dimensional feature space. Second, a damaged region is restored in the converted feature space. Finally, inverse conversion is performed from the lower dimensional
							space to the original space.
						</p>
						<!-- Table Top Shadow Interface -->
						<p>
							<span class="image left"><img src="images/research_projects/shadow.jpg" alt="" /></span>
							<strong>Making Graphical Information Visible in Real Shadows on Interactive Tabletops (IEEE TVCG 2014, <em>Invited at IEEE ISMAR 2014</em>).</strong>
							<br>
							<a href="http://daisukeiwai.org/en/research/shadow.html">[Project Page]</a>
							<br>
							We introduce a shadow-based interface for interactive tabletops. The proposed interface allows a user to browse graphical information by casting the shadow of his/her body, such as a hand, on a tabletop surface. Central to our technique is a new optical design that utilizes polarization in addition to the additive nature of light so that the desired graphical information is displayed only in a shadow area on a tabletop surface. In other words, our technique conceals the graphical information on surfaces other than the shadow area, such as the surface of the occluder and non-shadow areas on the tabletop surface. We combine the proposed shadow-based interface with a multi-touch detection technique to realize a novel interaction technique for interactive tabletops. We implemented a prototype system and conducted two proof-of-concept experiments along with a quantitative evaluation to assess the feasibility of the proposed optical design. Finally, we showed several implemented application systems of the proposed shadow-based interface.
						</p>
					</section>

					<!-- One -->
					<section id="Publications">
						<header class="major">
							<h2>Publications</h2>
						</header>
						<!-- Journal Papers -->
						<h3>Journal Papers</h3>
						<ol>
							<!-- <li>
								<u><isogawa>Mariko Isogawa</isogawa></u><i></i>
							</li> -->
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, Daisuke Iwai, Kosuke Sato, and Hideaki Kimata, "Which is the better inpainted image? Training data generation without any manual operations", <i>International Journal of Computer Vision (IJCV)</i>, to appear. 2018.
								<a href="https://link.springer.com/article/10.1007/s11263-018-1132-0">[Open Access Journal Paper]</a>
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Daisuke Iwai, Hideaki Kimata, and Kosuke Sato, "Mask Optimization for Image Inpainting", <i>IEEE Access</i>, to appear. 2018.
								<a href="https://ieeexplore.ieee.org/document/8502030">[Open Access Journal Paper]</a>
							</li>
							<li>
								Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, and Hideaki Kimata, "Extrinsic Camera Calibration of Display-Camera System with Cornea Reflections", <i>IEICE ED</i>, to appear, 2018.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, and Hideaki Kimata. "Image quality assessment for inpainted images via learning to rank", <i>Springer: Multimedia Tools and Applications (MTAP)</i>, to appear. 2018.
								<a href="https://link.springer.com/article/10.1007/s11042-018-6186-z">[Open Access Journal Paper]</a>
							</li>
							<li>
								Shogo Miyata, Hideo Saito, Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, and Akira Kojima. "Extrinsic Camera Calibration Without Visible Corresponding Points Using Omnidirectional Cameras", <i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</i>, vol.28, no.9, pp.2210-2219. 2018.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, and Akira Kojima. "Image and video completion via feature reduction and compensation", <i>Springer: Multimedia Tools and Applications (MTAP)</i>, vol.76, issue 7, pp. 9443-9462. 2017.
								<a href="https://link.springer.com/article/10.1007/s11042-016-3550-8">[Open Access Journal Paper]</a>
							</li>
							<li>
								Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, and Akira Kojima. "Extrinsic Camera Calibration with Minimal Conguration using Cornea Model and Equidistance Constraint", <i>IPSJ Transactions on Computer Vision and Applications (CVA)</i>, vol.8, pp.20-28. 2016.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Daisuke Iwai, and Kosuke Sato. "Making Graphical Information Visible in Real Shadows on Interactive Tabletops", <i>IEEE Transactions on Visualization and Computer Graphics (TVCG)</i>, vol. 20, No. 9, pp. 1293-1302. 2014. <em>(invited at ISMAR2014)</em>
							</li>
							<li>
								Marina Takeuchi, <u><isogawa>Mariko Isogawa</isogawa></u>, Daisuke Iwai, and Kosuke Sato. "Improvement of Operability by Loosing Spatial Relationship with Real Shadow on the Pointing Interface which Uses a Shadow Metaphor", <i>Transactions of the Virtual Reality Society of Japan</i>, vol.19, no.2, pp.207-214. 2014.
							</li>
						</ol>
						<!-- International Conference Papers -->
						<h3>International Conference Papers</h3>
						<ol>
							<!-- <li>
								<u><isogawa>Mariko Isogawa</isogawa></u><i></i>
							</li> -->
							<li>
								Yuta Kageyama, <u><isogawa>Mariko Isogawa</isogawa></u>, Daisuke Iwai, and Kosuke Sato, "Generative Adversarial Network Based Image Blur Compensation for Projection-Based Mixed Reality", <i>IEEE 8th Global Conference on Consumer Electronics (GCCE)</i>, 2019.
							</li>
							<li>
								Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, Yoshinori Kusachi, Naoki Saijo, "VR-based Batter Training System with Motion Sensing and Performance Visualization", <i>IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR), Domo</i>, 2019.
							</li>
							<li>
								Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, and Hideaki Kimata. "Human Pose as Calibration Pattern; 3D Human Pose Estimation with Multiple Unsynchronized and Uncalibrated Cameras", The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp.1775-1782, 2018.
							</li>
							<li>
								Tomoya Kaichi, Hideo Saito, Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, and Hideaki Kimata. "Estimation of Center of Mass for Sports Scene Using Weighted Visual hull", The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp.1809-1815, 2018.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Takehiro Fukuda, Naoki Saijo, Kosuke Takahashi, Hideaki Kimata, and Makio Kashino. "What Can VR Syetems Tell Sports Players? Reaction-Based Analysis of Baseball Batters in Virtual and Real Worlds", The 25th IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR), pp.587-588, 2018.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, and Hideaki Kimata. "Which is the better inpainted image? Learning without subjective annotation", British Machine Vision Conference (BMVC), Spotlight (acceptance rate: 8.8%) 2017.
							</li>
							<li>
								Shogo Miyata, Hideo Saito, Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, and Hideaki Kimata. "Ball 3D Trajectory Reconstruction without Preliminary Temporal and Geometrical Camera Calibration", The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp.164-169, 2017.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, and Akira Kojima. "Eye gaze analysis and learning-to-rank to obtain the most preferred result in image inpainting", IEEE International Conference on Image Processing (ICIP), pp.3538-3542, 2016.
							</li>
							<li>
								Kosuke Takahashi, Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, and Akira Kojima. "Cornea-reection-based Extrinsic Camera Calibration without a Direct View", International Conference on Computer Vision Theory and Application (VISAPP), pp.15-24, 2016.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, and Akira Kojima. "Virtual Omnidirectional Video Synthesis with Multiple Cameras for Sports Training", 3rd International Congress on Sports Sciences Research and Technology Support (icSPORTS), pp.271-275, 2015.
							</li>
							<li>
								Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, Kosuke Takahashi, Hideaki Takada, and Akira Kojima. "Immersive Previous Experience in VR for Sports Performance Enhancement", 3rd International Congress on Sports Sciences Research and Technology Support (icSPORTS), 2015.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, and Akira Kojima. "Content Completion in Lower Dimensional Feature Space through Feature Reduction and Compensation", IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp.156-159, 2015.
							</li>
							<li>
								<u><isogawa>Mariko Isogawa</isogawa></u>, Dan Mikami, Kosuke Takahashi, and Akira Kojima. "Toward Enhancing Robustness of DR System: Ranking Model for Background Inpainting", IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp.178-179, 2015.
							</li>
							<li>
								Dan Mikami, <u><isogawa>Mariko Isogawa</isogawa></u>, Kosuke Takahashi, and Akira Kojima. "Automatic Visual Feedback from Multiple Views for Motor Learning", IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp.212-213, 2015.
							</li>
							<li>
								Marina Takeuchi, <u><isogawa>Mariko Isogawa</isogawa></u>, Daisuke Iwai, Kosuke Sato. "Weak Perspective Shadow Interface for Seated User's Pointing on Large Wall Display", In Proceedings of IEEE/SICE International Symposium on System Integration (SII), pp.316-321, 2014.
							</li>
							<li>
								<u><isogawa>Mariko Miki</isogawa></u>, Daisuke Iwai, and Kosuke Sato. "Optically Hiding of Information with Polarized Complementary Projection", In Proceedings of International Conference on Articial Reality and Telexistence (ICAT), pp.166, 2011.
							</li>
							<li>
								<u><isogawa>Mariko Miki</isogawa></u>, Daisuke Iwai, and Kosuke Sato. "Optically Hiding of Tabletop Information with Polarized Complementary Image Projection - Your Shadow Reveals It!", In Proceedings of ACM International Conference on Interactive Tabletops and Surfaces (ITS), pp.260-261, 2011.
							</li>
							<!-- <li></li> -->
							<!-- <li></li> -->
							<!-- <li></li> -->
						</ol>
						<!-- Domestic Conference Papers -->
						<h3>Domestic Conference Papers</h3>
							<!-- Pointer for folding -->
							<div onclick="obj=document.getElementById('open_domestic_paper').style; obj.display=(obj.display=='none')?'block':'none';">
								<a style="cursor:pointer;">Click here to review domestic conference papers</a>
							</div>
							<!-- Body for folding -->
							<div id="open_domestic_paper" style="display:none;clear:both;">
								<ol>
									<li>
										高橋康輔, 三上弾, 五十川麻理子, 草地良規. "Dance Dance Calibration: 非同期かつ未校正な多視点カメラを用いた人体関節の三次元位置推定", 第19回画像の認識・理解シンポジウム(MIRU), 2019. <em>(MIRU インタラクティブ発表賞)</em>
									</li>
									<li>
										影山雄太, 五十川麻理子, 岩井大輔, 佐藤宏介. "敵対的生成ネットワークを用いた投影型複合現実感のための実時間ボケ補償",　第19回画像の認識・理解シンポジウム(MIRU), 2019.
									</li>
									<li>
										影山雄太, 五十川麻里子, 岩井大輔, 佐藤宏介. "敵対的生成ネットワークを用いた映像投影時に生じるブラー補償", 第63回システム制御情報学会研究発表講演会講演論文集(SCI'19), pp.1438-1445, 2019.
									</li>
									<li>
										五十川麻理子, 三上弾, 岩井大輔, 草地良規, 佐藤宏介. "画像インペインティングのための低主観品質領域の位置推定", 第18回画像の認識・理解シンポジウム(MIRU), 2018. <em>(MIRU インタラクティブ発表賞)</em>
									</li>
									<li>
										高橋康輔, 三上弾, 五十川麻理子, 木全英明. "人体関節を利用した多視点カメラの外部キャリブレーション法の検討", 情報処理学会研究報告, CVIM 研究会, 2017-CVIM-209, no.30, pp.1-8, 2017.
									</li>
									<li>
										鶏内朋也，斎藤英雄，高橋康輔, 三上弾, 五十川麻理子, 木全英明. "複数視点画像を用いた人体の重心位置推定手法の検討", 電子情報通信学会技術研究報告, MVE 研究会, vol.117, no.252, pp.19-23, 2017.
									</li>
									<li>
										松本鮎美, 三上弾, 高橋康輔, 五十川麻理子, 木全英明. "低次元空間における時間補間に基づくイベントタイミング検出", 電子情報通信学会技術研究報告MVE 研究会, vol.116, no.496, pp.1-5, 2017.
									</li>
									<li>
										宮田省吾, 斎藤秀雄, 高橋康輔, 三上弾, 五十川麻理子, 木全英明. "野球のボール追跡による多視点カメラの時間的および幾何学的キャリブレーションとボールの3 次元軌跡復元", 情報処理学会研究報告, CVIM 研究会, 2017-CVIM-205, no.40, pp.1-5, 2017.
									</li>
									<li>
										宮田省吾, 斎藤秀雄, 高橋康輔, 三上弾, 五十川麻理子, 木全英明. "全天球カメラを用いた重複視野を持たないカメラ間の外部キャリブレーション", 第19 回画像の認識・理解シンポジウム(MIRU), 2016.
									</li>
									<li>
										五十川麻理子, 三上弾, 高橋康輔，小島明. "ランキング学習を用いたインペインティング画像の選好順序推定法", 電子情報通信学会技術研究報告MVE 研究会, vol.115, no.245, p.49-54, 2015.
									</li>
									<li>
										高橋康輔，三上弾，五十川麻理子, 小島明. "眼球を利用したカメラとその視野外に存在する物体の外部キャリブレーション", 電子情報通信学会技術研究報告MVE 研究会, vol.115, no.245, p.61-66, 2015.
									</li>
									<li>
										高橋康輔，三上弾，五十川麻理子, 小島明. "眼球を用いたカメラとその視野外に存在する物体の最小構成外部キャリブレーション", 第18 回画像の認識・理解シンポジウム(MIRU), 2015.
									</li>
									<li>
										五十川麻理子, 三上弾, 高橋康輔，小島明. "特徴量の削減と合成に基づく低次元特徴量空間を用いたコンテンツコンプリーション", 電子情報通信学会技術研究報告MVE研究会, vol.115, no.76, p.37-42, 2015.
									</li>
									<li>
										高橋康輔，三上弾，五十川麻理子, 小島明. "複数カメラ映像を用いた仮想全天球映像合成に関する検討", 電子情報通信学会技術研究報告MVE 研究会, vol.115, no.76, p.43-48, 2015.
									</li>
									<li>
										小山田雄仁，五十川麻理子, 森尚平，藤本雄一郎，武富貴史. "ISMAR2014 会議報告", 情報処理学会コンピュータビジョンとイメージメディア研究会（CVIM）, 2015-CVIM-195(23), 2015.
									</li>
									<li>
										五十川麻理子, 三上弾, 小島明. "特徴量の削減と合成に基づく体感品質に優れた画像修復", 電子情報通信学会技術研究報告MVE 研究会, vol.114, no.239, p.37-42 2014. <em>(電子情報通信学会MVE賞)</em>
									</li>
									<li>
										三上弾, ビエンホアンハイ, 越智大介, 五十川麻理子, 小澤史郎, 小島明. "体感品質の良い他視点映像提示手法", 電子情報通信学会技術研究報告MVE 研究会, vol.114, no.114, p.7-12 2014.
									</li>
									<li>
										三木麻理子, 岩井大輔, 佐藤宏介. "インタラクティブテーブルトップのための補色偏光投影による実影のみでアクセス可能な映像情報隠蔽", 情報処理学会, インタラクション2012 論文集, pp.97-104, 2012.
									</li>
									<li>
										三木麻理子, 岩井大輔, 佐藤宏介. "補色多重化偏光投影による実影のみでアクセス可能な映像情報隠蔽", 電子情報通信学会技術研究報告(第36 回複合現実感研究会), vol. 111, no. 379, pp.139-144, 2012.
									</li>
									<li>
										三木麻理子, 岩井大輔, 佐藤宏介. "ShadowDemultiplexer: 補色多重化偏光投影による実影のみでアクセス可能な映像情報隠蔽", 情報処理学会, インタラクション2011 論文集, pp.809-812, 2011.
									</li>
								</ol>
							</div>
					</section>

					<!-- Talks -->
					<section id="Talks">
						<header class="major">
							<h2>Talks</h2>
						</header>
						<ul>
							<li><strong>Kumamoto University</strong> 'Recent Advances in Inpainting and its Subjective Quality Assessment', 2018.</li>
							<li><strong>Sojo University</strong> 'Recent Advances in learning based image and video processing', 2018.</li>
							<li><strong>IEICE Technical Group on Signal Processing (SIP)</strong> 'Recent Advances in Inpainting and its Subjective Quality Assessment', 2018.</li>
							<li><strong>International workshop on Diminished Reality (IWDR), IEEE ISMAR</strong> 'Image Inpainting for Diminished Reality', 2016.</li>
							<li><strong>IEEE TVCG Special Session, IEEE ISMAR</strong> 'Making Graphical Information Visible in Real Shadows on Interactive Tabletops', 2014.</li>
						</ul>
					</section>

					<!-- Award -->
					<section id="Award_and_Honor">
						<header class="major">
							<h2>Award&Honor</h2>
						</header>
						<ul>
							<li><strong>MIRU Interactive Session Award (Best Poster Paper Award)</strong>, The 22st Meeting on Image Recognition and Understanding (MIRU), 2019.</li>
							<li><strong>NTT メディアインテリジェンス研究所 所長表彰 特別賞</strong>(社内表彰), 2019.</li>
							<li><strong>MIRU Interactive Session Award (Best Poster Paper Award)</strong>, The 21st Meeting on Image Recognition and Understanding (MIRU), 2018.</li>
							<li><strong>NTT President Award</strong>(社内表彰), 2017.</li>
							<li><strong>NTT サービスイノベーション総合研究所研究開発奨励賞</strong>(社内表彰), 2015.</li>
							<li><strong>NTT 知的財産センタ所長表彰</strong>(社内表彰), 2015.</li>
							<li><strong>MVE Award (Best Presentation Award)</strong>, IEICE Technical Committee on Media Experience and Virtual Environment (MVE), 2014.</li>
							<li><strong>1st Class Honor in Master Course</strong>, System Innovation Course, Graduate School of Engineering Science, Osaka University, 2013.</li>
						</ul>
					</section>

					<!-- Academic Services -->
					<section id="Academic_Service">
						<header class="major">
							<h2>Academic Service</h2>
						</header>
							<!-- Committee -->
							<h4>Organization Committee</h4>
							<ul>
								<li><strong>ACCV 2020</strong> (Financial Chair)</li>
								<li><strong>MIRU 2018, 2019</strong> (Area Chair)</li>
								<li><strong>MIRU 2017</strong> (Committee for young researcher's program)</li>
							</ul>
							<!-- Review -->
							<h4>Peer-Reviewer</h4>
							<ul>
								<li><strong>ACM SIGGRAPH Asia</strong> (2018, 2017)</li>
								<li><strong>IEEE TCSVT</strong> (2018, 2017)</li>
								<li><strong>IEEE Access</strong> (2019)</li>
								<li><strong>IEICE Trans. on Information and Systems</strong> (2019, 2018, 2017, 2016, 2015)</li>
								etc..
							</ul>
					</section>
			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<!-- <li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="#" class="icon fa-github"><span class="label">Github</span></a></li>
						<li><a href="#" class="icon fa-dribbble"><span class="label">Dribbble</span></a></li>
						<li><a href="#" class="icon fa-envelope-o"><span class="label">Email</span></a></li> -->
					</ul>
					<ul class="copyright">
						<li>&copy; Untitled</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
